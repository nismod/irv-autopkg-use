{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1676347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e704cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pyproj import Geod\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import rioxarray\n",
    "import rasterio\n",
    "from shapely.geometry import LineString\n",
    "from snail.core.intersections import split_linestring\n",
    "from snail.core.intersections import get_cell_indices as get_cell_indicies_of_midpoint\n",
    "from scipy.integrate import simpson\n",
    "\n",
    "from utils import aqueduct_rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c54572",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "country_iso = \"bgd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb2c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flood hazard data to use, pulled from the autopkg API\n",
    "epoch = 2050\n",
    "scenario = \"rcp4p5\"\n",
    "raster_paths = glob(f\"data/{country_iso}/wri_aqueduct/*{scenario}*{epoch}*.tif\")\n",
    "raster_paths = sorted(raster_paths, key=aqueduct_rp, reverse=True)\n",
    "\n",
    "network = gpd.read_file(f\"data/{country_iso}/gri_osm/{country_iso}.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33976ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_raster_grid_consistent(raster_paths: list[str]) -> None:\n",
    "    \"\"\"\n",
    "    Check a set of rasters are on the same grid.\n",
    "    \"\"\"\n",
    "    if len(raster_paths) > 1:\n",
    "        reference, *others = raster_paths\n",
    "\n",
    "        with rasterio.open(reference) as dataset:\n",
    "            raster_width = dataset.width\n",
    "            raster_height = dataset.height\n",
    "            raster_transform = list(dataset.transform)\n",
    "\n",
    "        # check all raster files use the same grid\n",
    "        for raster_path in others:\n",
    "            with rasterio.open(raster_path) as raster:\n",
    "                if (\n",
    "                    raster_width != raster.width\n",
    "                    or raster_height != raster.height\n",
    "                    or raster_transform != list(raster.transform)\n",
    "                ):\n",
    "                    raise AttributeError(\n",
    "                        (\n",
    "                            f\"Raster attribute mismatch in file {raster_path}:\\n\"\n",
    "                            f\"Height: expected={raster_height}; actual={raster.height}\\n\"\n",
    "                            f\"Width: expected={raster_width}; actual={raster.width}\\n\"\n",
    "                            f\"Transform equal? {'True' if list(raster.transform) == raster_transform else 'False'}\"\n",
    "                        )\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71771fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_linestrings(features: gpd.GeoDataFrame, raster: rasterio.io.DatasetReader) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Split feature linestrings on a raster grid\n",
    "    \"\"\"\n",
    "    \n",
    "    if set(features.geometry.type) != {\"LineString\"}:\n",
    "        raise ValueError(\"Can only split LineString geometries\")\n",
    "    \n",
    "    all_splits = []\n",
    "    all_indicies = []\n",
    "    for edge in features.itertuples():\n",
    "        split_geoms = split_linestring(\n",
    "            edge.geometry,\n",
    "            raster.width,\n",
    "            raster.height,\n",
    "            list(raster.transform),\n",
    "        )\n",
    "        all_splits.extend(split_geoms)\n",
    "        all_indicies.extend([edge.Index] * len(split_geoms))\n",
    "\n",
    "    return gpd.GeoDataFrame({\"original_index\": all_indicies, \"geometry\": all_splits})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b261a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_indicies_assigner(raster: rasterio.io.DatasetReader) -> Callable:\n",
    "    \"\"\"\n",
    "    Given an open raster, return a function that can check a geometry against the\n",
    "    raster grid and return grid cell indicies for that geometry.\n",
    "    \"\"\"\n",
    "    \n",
    "    def cell_indicies_of_split_geometry(geometry, *args, **kwargs) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Given a geometry, find the cell index (i, j) of its midpoint for the\n",
    "        enclosing raster parameters.\n",
    "\n",
    "        N.B. There is no checking whether a geometry spans more than one cell.\n",
    "        \"\"\"\n",
    "\n",
    "        # integer indicies\n",
    "        i, j = get_cell_indicies_of_midpoint(geometry, raster.height, raster.width, raster.transform)\n",
    "\n",
    "        # die if we're out of bounds somehow\n",
    "        assert 0 <= i < raster.width\n",
    "        assert 0 <= j < raster.height\n",
    "\n",
    "        # return a series with labels so we can unpack neatly into two dataframe columns\n",
    "        return pd.Series(index=(\"raster_i\", \"raster_j\"), data=[i, j])\n",
    "   \n",
    "    return cell_indicies_of_split_geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2890d4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to linestrings (edges)\n",
    "lines = network[network.geometry.type == \"LineString\"]\n",
    "\n",
    "# error if grids not consistent\n",
    "check_raster_grid_consistent(raster_paths)\n",
    "\n",
    "# split edges on raster grid\n",
    "raster_path, *other_raster_paths = raster_paths\n",
    "raster = rasterio.open(raster_path)\n",
    "splits = split_linestrings(lines, raster)\n",
    "\n",
    "# calculate split edge lengths\n",
    "geod = Geod(ellps=\"WGS84\")\n",
    "meters_per_km = 1_000\n",
    "splits[\"length_km\"] = splits.geometry.apply(geod.geometry_length) / meters_per_km\n",
    "\n",
    "# which cell is each split edge in?\n",
    "assigner = cell_indicies_assigner(raster)\n",
    "raster_indicies = splits.geometry.apply(assigner)\n",
    "\n",
    "# join raster indicies to geometries with shared index\n",
    "splits_with_raster_indicies = splits.join(raster_indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223eb3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map raster indicies as visual check\n",
    "f, (ax_i, ax_j) = plt.subplots(ncols=2)\n",
    "splits_with_raster_indicies.plot(ax=ax_i, column=\"raster_i\", cmap=\"viridis\", legend=True)\n",
    "ax_i.set_title(\"raster_i\")\n",
    "splits_with_raster_indicies.plot(ax=ax_j, column=\"raster_j\", cmap=\"cubehelix\", legend=True)\n",
    "ax_j.set_title(\"raster_j\")\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_lookup(df: pd.DataFrame, fname: str, band_number: int=1) -> pd.Series:\n",
    "    \"\"\"\n",
    "    For each split geometry, lookup the relevant raster value. Cell indicies\n",
    "    must have been previously calculated and stored as \"raster_i\" and \"raster_j\".\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Table of features, each with cell indicies pertaining\n",
    "            to relevant raster pixel. Indicies must be stored under columns with\n",
    "            names referenced by fields.RASTER_I and fields.RASTER_J\n",
    "        fname (str): Filename of raster file to read data from\n",
    "        band_number (int): Which band of the raster file to read\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Series of raster values, with same row indexing as df.\n",
    "    \"\"\"\n",
    "\n",
    "    with rasterio.open(fname) as dataset:\n",
    "\n",
    "        band_data: np.ndarray = dataset.read(band_number)\n",
    "            \n",
    "        # set non-positive values to NaN\n",
    "        band_data[band_data < 1E-6] = np.nan\n",
    "\n",
    "        # 2D numpy indexing is j, i (i.e. row, column)\n",
    "        return pd.Series(index=df.index, data=band_data[df[\"raster_j\"], df[\"raster_i\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9945d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in raster_paths:\n",
    "    splits_with_raster_indicies[f\"rp-{aqueduct_rp(path)}\"] = raster_lookup(splits_with_raster_indicies, path)\n",
    "    \n",
    "hazard_intensities = splits_with_raster_indicies\n",
    "hazard_intensities.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbeef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_min(x: float | np.ndarray, L: float, m: float, k: float, x_0: float) -> float | np.ndarray:\n",
    "    \"\"\"\n",
    "    Logistic function with a minimum value, m.\n",
    "\n",
    "    Args:\n",
    "        x: Input values\n",
    "        L: Maximum output value\n",
    "        m: Minimum output value\n",
    "        k: Steepness parameter\n",
    "        x_0: Location of sigmoid centre in x\n",
    "\n",
    "    Returns:\n",
    "        Output values\n",
    "    \"\"\"\n",
    "\n",
    "    return m + (L - m) / (1 + np.exp(-k * (x - x_0)))\n",
    "\n",
    "# define a damage function\n",
    "damage_curve = lambda x: logistic_min(x, 1, 0, 2, 2)\n",
    "\n",
    "# have a look at it\n",
    "f, ax = plt.subplots()\n",
    "x = np.linspace(0, 5, 20)\n",
    "ax.scatter(x, damage_curve(x))\n",
    "ax.set_xlabel(\"Flood depth [meters]\")\n",
    "ax.set_ylabel(\"Damage fraction\")\n",
    "ax.set_title(\"Damage function\")\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72393e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate how badly each split edge is damaged by the flooding\n",
    "damage_fractions = hazard_intensities.copy()\n",
    "hazard_cols = [col for col in hazard_intensities.columns if col.startswith(\"rp-\")]\n",
    "damage_fractions[hazard_cols] = damage_fractions[hazard_cols].applymap(damage_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955bb37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the cost of damage\n",
    "reconstruction_cost_currency_per_km = 1E4\n",
    "\n",
    "damage_cost = damage_fractions.copy()\n",
    "for col in hazard_cols:\n",
    "    damage_cost[col] = damage_cost[col] * damage_cost.length_km * reconstruction_cost_currency_per_km\n",
    "\n",
    "grouped_damage_cost = damage_cost[hazard_cols].groupby(damage_cost.original_index).sum()\n",
    "probability_per_year = 1 / np.array([int(col.replace(\"rp-\", \"\")) for col in hazard_cols])\n",
    "\n",
    "damage_probability_curve = grouped_damage_cost.copy()\n",
    "damage_probability_curve.columns = probability_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcd1fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the damage-probability curve\n",
    "f, ax = plt.subplots()\n",
    "damage_probability_sum = damage_probability_curve.sum()\n",
    "damage_probability_sum.plot(ax=ax)\n",
    "ax.grid()\n",
    "ax.set_xlabel(\"Probability per given year\")\n",
    "ax.set_ylabel(\"Damage cost [currency]\")\n",
    "ax.set_title(f\"Damage-probability curve\\n{scenario.upper()} {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19349f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EAD = lines[[\"geometry\"]].copy()\n",
    "EAD[\"ead\"] = simpson(grouped_damage_cost, x=probability_per_year, axis=1)\n",
    "f, ax = plt.subplots(figsize=(10,10))\n",
    "EAD.plot(\n",
    "    ax=ax,\n",
    "    column=\"ead\",\n",
    "    legend=True,\n",
    "    cmap=\"RdPu\",\n",
    "    norm=matplotlib.colors.LogNorm(vmin=1E0, vmax=EAD.ead.max())\n",
    ")\n",
    "ax.grid()\n",
    "ax.set_title(f\"Expected Damages [currency per annum]\\nTotal: {EAD.ead.sum():.2E}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
